# 第三章 系统设计与算法实现 (System Design & Implementation)

## 3.1 总体架构设计 (System Architecture)

### 3.1.1 混合专家架构 (Mixture of Experts, MoE)

Deep-SCL-Cat 系统采用混合专家架构，将复杂的学业风险预测任务分解为多个专业化子模块，每个模块专注于特定功能，通过流水线方式协同工作。该架构的核心思想是"分而治之"，通过模块化设计提高系统的可解释性、可维护性和预测性能。

系统架构包含四个核心专家模块：
1. **数据专家 (Data Expert)**: 负责数据加载、清洗和语义化处理
2. **聚类专家 (Cluster Expert)**: 负责发现数据中的潜在异质性模式
3. **预测专家 (Prediction Expert)**: 负责构建精准的分类预测模型
4. **策略专家 (Strategy Expert)**: 负责优化决策阈值和业务策略

### 3.1.2 四层流线架构 (Four-Layer Pipeline)

系统实现"Data-Cluster-Model-Strategy"的四层流线架构，如图3-1所示：

```
┌─────────────────────────────────────────────────────────────┐
│                    Deep-SCL-Cat 工作流                        │
├───────────────┬──────────────┬─────────────┬───────────────┤
│   数据层       │   聚类层      │   模型层     │   策略层       │
│  (Data Layer) │ (Cluster Layer)│ (Model Layer)│ (Strategy Layer)│
├───────────────┼──────────────┼─────────────┼───────────────┤
│ 1. 数据加载    │ 3. 特征选择   │ 5. 模型训练  │ 7. 阈值寻优    │
│ 2. 数据清洗    │ 4. K-Means聚类│ 6. 模型评估  │ 8. 策略部署    │
└───────────────┴──────────────┴─────────────┴───────────────┘
```

在 `main.py` 中的具体实现流程如下：

```python
# Step 1: 数据加载 (Data Loading)
cleaned_data = data_loader.load_and_clean_data()

# Step 2: 聚类特征工程 (Clustering Feature Engineering)
df_clustered, kmeans, X_scaled, feature_columns = feature_cluster.process_clustering()

# Step 3: 模型训练 (Model Training)
model, X_test, y_test = model_catboost.train_model()

# Step 4: 策略寻优 (Strategy Optimization)
optimal_threshold = strategy_recall.find_optimal_threshold()

# Step 5: 解释性分析 (Explainability Analysis)
explainability.explain_model()
```

这种流线设计确保了数据处理的一致性和可重复性，每个模块的输出作为下一个模块的输入，形成端到端的自动化工作流。

## 3.2 数据预处理与语义化 (Data Preprocessing)

### 3.2.1 缺失值处理策略 (Missing Value Imputation Strategy)

针对SCL-90心理评估数据中常见的缺失值问题，系统采用基于缺失比例的差异化处理策略：

1. **低缺失比例 (<5%)**: 直接删除含有缺失值的样本行
2. **高缺失比例 (≥5%)**: 采用中位数填充（数值特征）或众数填充（分类特征）

数学表达为：
$$
\text{处理策略}(x_i) = 
\begin{cases} 
\text{删除行}, & \text{if } \frac{\text{缺失数}(x_i)}{N} < 0.05 \\
\text{中位数填充}, & \text{if } \frac{\text{缺失数}(x_i)}{N} \geq 0.05 \text{ 且 } x_i \in \mathbb{R} \\
\text{众数填充}, & \text{otherwise}
\end{cases}
$$

在 `src/data_loader.py` 中的实现：
```python
# 处理缺失值
for col in df.columns:
    if missing_counts[col] > 0:
        missing_pct = missing_percentage[col]
        
        if missing_pct < 5:
            # 缺失比例小于5%，删除含有缺失值的行
            df = df.dropna(subset=[col])
        else:
            # 缺失比例大于等于5%，用中位数填充
            if pd.api.types.is_numeric_dtype(df[col]):
                median_val = df[col].median()
                df[col] = df[col].fillna(median_val)
```

### 3.2.2 SCL-90因子语义化映射 (SCL-90 Factor Semantic Mapping)

为解决原始数据中因子名称（score1-score10）难以理解的问题，系统建立了语义化映射机制，将技术性列名转换为心理学专业术语。

在 `src/config.py` 中定义的映射关系：
```python
SCL90_FACTOR_MAP = {
    'score1': '躯体化',
    'score2': '强迫症状',
    'score3': '人际敏感',
    'score4': '抑郁',
    'score5': '焦虑',
    'score6': '敌对',
    'score7': '恐怖',
    'score8': '偏执',
    'score9': '精神病性',
    'score10': '其他(睡眠饮食)'
}
```

语义化转换公式：
$$
\text{特征名}_{\text{语义化}} = f(\text{特征名}_{\text{原始}}) = \text{SCL90\_FACTOR\_MAP}[\text{特征名}_{\text{原始}}]
$$

该映射不仅提高了系统的可解释性，还确保了后续分析结果能够被心理学专业人员直接理解和使用。

## 3.3 基于K-Means的异质性分层 (Latent Pattern Discovery)

### 3.3.1 聚类动机：解决样本异质性 (Clustering Motivation: Addressing Sample Heterogeneity)

SCL-90心理评估数据通常存在显著的个体差异，不同学生群体可能表现出不同的心理症状模式。直接在所有样本上训练单一预测模型会忽略这种异质性，导致模型泛化能力下降。K-Means聚类通过无监督学习发现数据中的潜在子群体，为后续的预测模型提供先验知识。

聚类目标函数（惯性最小化）：
$$
J = \sum_{i=1}^{n} \sum_{k=1}^{K} w_{ik} \| \mathbf{x}_i - \boldsymbol{\mu}_k \|^2
$$
其中：
- $n$ 为样本数
- $K$ 为聚类数（本系统设置为3）
- $w_{ik} \in \{0,1\}$ 表示样本 $i$ 是否属于聚类 $k$
- $\boldsymbol{\mu}_k$ 为聚类 $k$ 的中心

### 3.3.2 特征选择与标准化 (Feature Selection and Standardization)

聚类过程仅使用SCL-90的10个核心心理因子，排除年龄、性别等人口学变量，确保聚类结果纯粹反映心理症状模式。

在 `src/feature_cluster.py` 中的实现：
```python
# 明确选择SCL-90中文特征列
feature_columns = [c for c in df.columns if c in config.SCL90_FEATS]

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

标准化公式（Z-score标准化）：
$$
z_{ij} = \frac{x_{ij} - \mu_j}{\sigma_j}
$$
其中：
- $x_{ij}$ 为样本 $i$ 在特征 $j$ 上的原始值
- $\mu_j$ 为特征 $j$ 的均值
- $\sigma_j$ 为特征 $j$ 的标准差

### 3.3.3 聚类结果作为先验知识 (Clustering Results as Prior Knowledge)

聚类标签 `Cluster_Label` 作为类别特征被整合到后续的预测模型中，为CatBoost模型提供样本所属子群体的先验信息。这种设计使模型能够学习不同子群体的风险模式差异，提高预测准确性。

## 3.4 CatBoost混合专家预测模型 (Prediction Model)

### 3.4.1 算法选择依据：Ordered Boosting对抗小样本过拟合

CatBoost（Categorical Boosting）被选为核心预测算法，主要基于以下优势：

1. **Ordered Boosting机制**：有效对抗小样本数据中的过拟合问题
2. **原生类别特征支持**：无需独热编码即可处理 `Cluster_Label` 等类别特征
3. **自动处理缺失值**：内置缺失值处理机制
4. **对称树结构**：提高模型泛化能力和推理速度

Ordered Boosting的数学原理：
$$
\frac{\partial L(y_i, F(\mathbf{x}_i))}{\partial F(\mathbf{x}_i)} \approx \frac{\partial L(y_i, F^{\sigma(j)}(\mathbf{x}_i))}{\partial F(\mathbf{x}_i)}
$$
其中 $\sigma(j)$ 表示在排列 $\sigma$ 中位于样本 $j$ 之前的样本索引。

### 3.4.2 类别不平衡处理机制 (Class Imbalance Handling)

针对学业风险预测中高危样本稀少的问题，系统采用 `auto_class_weights='Balanced'` 参数自动调整类别权重：

```python
model = CatBoostClassifier(
    auto_class_weights='Balanced',  # 自动处理样本不平衡
    # ... 其他参数
)
```

类别权重计算公式：
$$
w_{\text{class}} = \frac{n_{\text{samples}}}{n_{\text{classes}} \times n_{\text{samples\_class}}}
$$

这种机制确保模型在训练过程中给予少数类（高危学生）更多关注，提高召回率。

### 3.4.3 聚类标签的整合 (Integration of Cluster Labels)

聚类标签作为类别特征被纳入模型训练，使CatBoost能够学习不同心理画像子群体的风险模式差异：

```python
# 识别类别特征
categorical_features = []
if 'Cluster_Label' in X.columns:
    categorical_features = ['Cluster_Label']
    
model = CatBoostClassifier(
    cat_features=categorical_features,  # 指定类别特征
    # ... 其他参数
)
```

这种设计实现了"聚类-预测"的协同效应，聚类结果指导预测模型的学习方向，预测结果反过来验证聚类的有效性。

## 3.5 高召回率阈值移动策略 (Recall Optimization Strategy)

### 3.5.1 业务原则："宁可误报，不可漏报"

在学业风险预警场景中，漏报高危学生的代价远高于误报正常学生。因此，系统采用"宁可误报，不可漏报"的业务原则，优先保证高危学生的识别率（召回率）。

决策规则：
$$
\text{预测为高危} = 
\begin{cases} 
1, & \text{if } P(\text{高危} \mid \mathbf{x}) > \tau_{\text{optimal}} \\
0, & \text{otherwise}
\end{cases}
$$
其中 $\tau_{\text{optimal}}$ 为优化后的决策阈值。

### 3.5.2 基于P-R曲线的阈值寻优 (Threshold Optimization via P-R Curve)

系统通过精确率-召回率（Precision-Recall）曲线寻找满足召回率约束的最佳阈值：

在 `src/strategy_recall.py` 中的实现逻辑：
```python
def find_optimal_threshold():
    # 计算不同阈值下的精确率和召回率
    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_proba)
    
    # 寻找召回率 > 95% 的最小阈值
    target_recall = 0.95
    viable_thresholds = thresholds[recalls[:-1] >= target_recall]
    
    if len(viable_thresholds) > 0:
        optimal_threshold = viable_thresholds[0]  # 选择第一个满足条件的阈值
        return optimal_threshold
    else:
        return 0.5  # 默认阈值
```

优化目标：
$$
\tau_{\text{optimal}} = \min \{\tau \in [0,1] \mid \text{Recall}(\tau) \geq 0.95\}
$$

### 3.5.3 阈值应用与模型部署

寻优得到的最佳阈值 $\tau_{\text{optimal}} = 0.513$ 被应用于实际预测中。在Web交互界面中，该阈值作为风险判断的临界点：

```python
# 使用最佳阈值进行分类
best_threshold = 0.513
df_result['Risk_Label'] = (risk_probabilities > best_threshold).astype(int)
```

## 3.6 可解释性与可视化交互 (XAI & Interaction)

### 3.6.1 SHAP可解释性分析 (SHAP Explainability Analysis)

系统采用SHAP（SHapley Additive exPlanations）值进行模型可解释性分析，揭示各特征对预测结果的贡献度。

SHAP值的计算基于合作博弈理论：
$$
\phi_j = \sum_{S \subseteq \{1,\ldots,p\} \setminus \{j\}} \frac{|S|!(p-|S|-1)!}{p!} [f(S \cup \{j\}) - f(S)]
$$
其中：
- $\phi_j$ 为特征 $j$ 的SHAP值
- $p$ 为特征总数
- $S$ 为特征子集
- $f(S)$ 为使用特征子集 $S$ 的模型预测值

系统生成的可视化包括：
1. **特征重要性条形图**：展示各特征的平均绝对SHAP值
2. **SHAP摘要散点图**：展示特征值对预测的影响方向和程度
3. **SHAP依赖图**：展示关键特征与预测风险的非线性关系

### 3.6.2 双模式交互界面设计 (Dual-Mode Interaction Interface)

基于Streamlit框架构建的Web界面提供两种交互模式：

1. **单体预测模拟模式**：
   - 实时输入学生特征
   - 可视化预测流程（标准化→聚类→预测）
   - 个性化风险解读与建议

2. **批量智能筛查模式**：
   - 支持CSV/Excel文件上传
   - 自动批量处理与风险评估
   - 高危学生筛选与特征分析
   - 结果导出与报告生成

界面设计遵循"渐进式披露"原则，复杂功能隐藏在可展开区域中，确保界面简洁易用。同时，系统提供SCL-90因子的详细心理学释义，帮助用户理解各特征的专业含义。

### 3.6.3 实时反馈与决策支持 (Real-time Feedback & Decision Support)

系统不仅提供预测结果，还提供基于预测结果的处理建议：
- 对高危学生：建议一对一心理辅导、学业跟踪、家长沟通等措施
- 对正常学生：建议保持常规关注、鼓励参与集体活动等

这种设计将机器学习预测与教育干预实践紧密结合，形成"预测-解释-建议"的完整决策支持闭环。

---

**本章小结**：本章详细阐述了Deep-SCL-Cat系统的整体架构设计和算法实现。系统采用混合专家架构和四层流线设计，通过数据预处理、K-Means聚类、CatBoost预测和阈值优化等模块的协同工作，实现了高召回率的学业风险预警。SHAP可解释性分析和双模式交互界面进一步增强了系统的实用性和可接受性。实验结果表明，该系统在保证高召回率（>95%）的同时，保持了合理的精确率，能够有效支持学校心理健康教育工作。
