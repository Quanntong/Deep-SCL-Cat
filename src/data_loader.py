import os
import glob
import pandas as pd
import numpy as np
try:
    import src.config as config
except ImportError:
    import config

def standardize_columns(df):
    """
    æ ‡å‡†åŒ–åˆ—åï¼Œç»Ÿä¸€ä¸åŒå¹´ä»½çš„è¡¨å¤´å·®å¼‚
    """
    # 1. å»é™¤ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
    df.columns = df.columns.astype(str).str.strip().str.replace(r'\s+', '', regex=True)
    
    # 2. å…³é”®åˆ—åæ˜ å°„å­—å…¸
    column_mapping = {
        'äººé™…': 'äººé™…å…³ç³»æ•æ„Ÿ', 'äººé™…æ•æ„Ÿ': 'äººé™…å…³ç³»æ•æ„Ÿ',
        'å¼ºè¿«': 'å¼ºè¿«ç—‡çŠ¶', 
        'ç²¾ç¥': 'ç²¾ç¥ç—…æ€§', 
        'é¥®é£Ÿç¡çœ ': 'å…¶ä»–', 'é¥®é£Ÿ': 'å…¶ä»–', 'ç¡çœ ': 'å…¶ä»–', 
        'å…¶ä»–(é¥®é£Ÿç¡çœ )': 'å…¶ä»–', 'å› å­10': 'å…¶ä»–',
        'æŒ‚ç§‘æ•°': 'æŒ‚ç§‘æ•°ç›®', 'æŒ‚ç§‘': 'æŒ‚ç§‘æ•°ç›®', 'æŒ‚ç§‘æ•°é‡': 'æŒ‚ç§‘æ•°ç›®',
        'å¤‡æ³¨ï¼ˆå¼‚å¸¸å› å­æ•°ï¼‰': 'å¤‡æ³¨'
    }
    
    df = df.rename(columns=column_mapping)
    return df

def clean_numeric_column(series):
    """å¼ºåˆ¶è½¬æ•°å€¼ï¼Œéæ³•å­—ç¬¦å˜NaN"""
    return pd.to_numeric(series, errors='coerce')

def load_and_clean_data():
    print("\n" + "="*60)
    print(">>> [Data Loader] å¯åŠ¨ï¼šæ­£åœ¨æ‰«æ data/raw/ ...")
    print("="*60)
    
    # 1. æ‰«æç›®å½•ä¸‹æ‰€æœ‰csvå’Œxlsx
    raw_path = config.DATA_RAW
    all_files = glob.glob(os.path.join(raw_path, "*.*")) # æ‰«ææ‰€æœ‰æ–‡ä»¶
    
    valid_data_list = []
    
    for filepath in all_files:
        filename = os.path.basename(filepath)
        
        # === ğŸ›¡ï¸ å®‰å…¨è¿‡æ»¤æœºåˆ¶ ===
        # åªå¤„ç†æ–‡ä»¶ååŒ…å« "çº§" çš„æ–‡ä»¶
        if "çº§" not in filename:
            print(f"â© è·³è¿‡æ— å…³æ–‡ä»¶: {filename}")
            continue
            
        print(f"ğŸ“‚ æ­£åœ¨è¯»å–: {filename}")
        
        try:
            # 2. æ™ºèƒ½è¯»å–é€»è¾‘ (å…¼å®¹ä¼ªè£…æˆCSVçš„Excelæ–‡ä»¶)
            try:
                # ä¼˜å…ˆå°è¯•ä½œä¸º Excel è¯»å– (é’ˆå¯¹æ‚¨çš„ç‰¹æ®Šæƒ…å†µ)
                # å¦‚æœçœŸçš„æ˜¯CSVï¼Œread_excelå¯èƒ½ä¼šæŠ¥é”™ï¼Œä¹Ÿå¯èƒ½ä¸ä»…æŠ¥é”™
                if filename.lower().endswith('.xlsx') or filename.lower().endswith('.xls'):
                    df = pd.read_excel(filepath)
                else:
                    # å¯¹äº .csv åç¼€ï¼Œå…ˆè¯•ç€å½“ CSV è¯»
                    try:
                        df = pd.read_csv(filepath, encoding='utf-8-sig')
                    except:
                        try:
                            df = pd.read_csv(filepath, encoding='gbk')
                        except:
                            # å…³é”®ä¿®æ”¹ï¼šå¦‚æœCSVè¯»ä¸å‡ºæ¥ï¼Œå°è¯•ç”¨Excelå¼•æ“è¯»ï¼
                            print(f"   âš ï¸ CSVè§£ç å¤±è´¥ï¼Œå°è¯•ä½œä¸ºExcelæ ¼å¼è¯»å–...")
                            df = pd.read_excel(filepath)

            except Exception as e:
                print(f"   âŒ å½»åº•è¯»å–å¤±è´¥: {e}")
                continue

            # 3. æ ‡å‡†åŒ–ä¸æ¸…æ´—
            df = standardize_columns(df)
            df['Source_File'] = filename.split('.')[0] # è®°å½•æ¥æº
            
            # 4. æ£€æŸ¥å¿…è¦åˆ— (SCL-90)
            existing_features = [c for c in config.SCL90_FEATURES if c in df.columns]
            if len(existing_features) < 5:
                print(f"   âš ï¸ æ ¼å¼ä¸ç¬¦: ç¼ºå°‘SCL-90æ ¸å¿ƒåˆ—ï¼Œè·³è¿‡ã€‚")
                continue
                
            # è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±åˆ—
            missing_features = [c for c in config.SCL90_FEATURES if c not in df.columns]
            if missing_features:
                print(f"   ğŸ› ï¸ è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±åˆ—: {missing_features}")
                for col in missing_features:
                    df[col] = np.nan
            
            # 5. å¤„ç†æŒ‚ç§‘ç›®æ ‡åˆ—
            if config.TARGET_REGRESSION not in df.columns:
                print(f"   âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°'{config.TARGET_REGRESSION}'åˆ—ï¼Œé»˜è®¤è®¾ä¸º0")
                df[config.TARGET_REGRESSION] = 0
            else:
                fail_count = (pd.to_numeric(df[config.TARGET_REGRESSION], errors='coerce').fillna(0) > 0).sum()
                print(f"   âœ… æ•°æ®æœ‰æ•ˆ: åŒ…å« {fail_count} æ¡æŒ‚ç§‘è®°å½•")

            # ç­›é€‰æœ€ç»ˆåˆ—
            keep_cols = ['å­¦å·', 'å§“å', 'Source_File'] + config.SCL90_FEATURES + [config.TARGET_REGRESSION]
            keep_cols = [c for c in keep_cols if c in df.columns]
            
            valid_data_list.append(df[keep_cols])

        except Exception as e:
            print(f"   âŒ è¯»å–å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    # === åˆå¹¶ä¸åå¤„ç† ===
    if not valid_data_list:
        print("\nâŒ é”™è¯¯: æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼")
        return None

    full_df = pd.concat(valid_data_list, axis=0, ignore_index=True)
    print("\n>>> æ­£åœ¨åˆå¹¶ä¸æ¸…æ´—å…¨é‡æ•°æ®...")

    # 1. å¡«å…… SCL-90 ç¼ºå¤±å€¼
    for col in config.SCL90_FEATURES:
        full_df[col] = clean_numeric_column(full_df[col])
        full_df[col] = full_df[col].fillna(full_df[col].median())

    # 2. æ¸…æ´—æŒ‚ç§‘æ•°ç›®
    full_df[config.TARGET_REGRESSION] = clean_numeric_column(full_df[config.TARGET_REGRESSION]).fillna(0).astype(int)
    
    # 3. ç”ŸæˆäºŒåˆ†ç±»æ ‡ç­¾
    full_df[config.TARGET_CLASSIFICATION] = (full_df[config.TARGET_REGRESSION] > 0).astype(int)

    print(f"ğŸ‰ å¤„ç†å®Œæˆ!")
    print(f"   æ€»æ ·æœ¬é‡: {len(full_df)}")
    print(f"   æ€»æŒ‚ç§‘äººæ•°: {full_df[config.TARGET_CLASSIFICATION].sum()}")

    # ä¿å­˜
    config.make_dirs()
    save_path = os.path.join(config.DATA_PROCESSED, config.PROCESSED_FILE)
    full_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ æœ€ç»ˆæ•°æ®å·²ä¿å­˜è‡³: {save_path}")
    
    return full_df

if __name__ == "__main__":
    load_and_clean_data()